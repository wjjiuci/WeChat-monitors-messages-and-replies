import requests
from wxauto import WeChat
import time
import random
import os
import re
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from collections import deque

# ==================== é…ç½®åŒº ====================
TARGET_CONTACT = ""  #ç›‘å¬å¯¹è±¡çš„å¾®ä¿¡æ˜µç§°
SELF_NICKNAME = ""  #ç™»å½•å¾®ä¿¡æ˜µç§°
MODEL_DIR_NAME = f"{TARGET_CONTACT}_finetuned_model"
NON_TEXT_MESSAGES = {"[å›¾ç‰‡]", "[è§†é¢‘]", "[åŠ¨ç”»è¡¨æƒ…]", "[æ–‡ä»¶]", "[è¯­éŸ³]", "[é“¾æ¥]"}

# å¯¹è¯ä¸Šä¸‹æ–‡é…ç½®
MAX_HISTORY = 6  # æœ€å¤šè®°ä½ 6 æ¡æ¶ˆæ¯ï¼ˆ3è½®å¯¹è¯ï¼‰

# ==================== è‡ªå®šä¹‰é—®ç­”è§„åˆ™ ====================
# æ ¼å¼ï¼š{é—®é¢˜å…³é”®è¯: [å›å¤1, å›å¤2, ...]}
# æ”¯æŒæŒ‰é¡ºåºå›å¤ï¼ˆæ¯æ”¶åˆ°ä¸€ä¸ªé—®é¢˜ï¼ŒæŒ‰é¡ºåºè¿”å›ä¸€ä¸ªå›å¤ï¼‰
CUSTOM_QA_RULES = {
    "åœ¨å—": ["åˆšåœ¨å¬æ­Œå‘¢ï¼Œæ²¡çœ‹æ¶ˆæ¯", "å—¯ï¼Ÿå–Šæˆ‘å¹²å˜›", "æœ‰äº‹è¯´"],
    "ä½ å¥½": ["ä½ å¥½å–", "åˆè§é¢å•¦", "å—¨"],
    "å¿™": ["è¿˜å¥½å•¦ï¼Œå°±æ˜¯çœ‹çœ‹æ‰‹æœºã€‚ä½ å‘¢ï¼Ÿ", "åˆšåœ¨æ‰“æ¸¸æˆï¼Œæ€ä¹ˆäº†ï¼Ÿ", "æ­£èººç€å‘¢ï¼Œæœ‰å•¥äº‹ï¼Ÿ"],
    "åƒé¥­": ["åƒä»€ä¹ˆå‘¢ï¼Ÿæˆ‘è¿˜æ²¡æƒ³å¥½", "å•¥å¥½åƒçš„ï¼Ÿ", "æˆ‘ä¹Ÿé¥¿äº†"],
    "ç´¯": ["hhh,è¿™ä¹ˆå¹¸è‹¦", "ä¼‘æ¯ä¸€ä¸‹å§", "è¦ä¸è¦æˆ‘ç»™ä½ ææè‚©ï¼Ÿ"],
    "æƒ³ä½ ": ["å°Šæ¸¡å‡å˜Ÿï¼Œä½ è¿™æ ·è®©æˆ‘å¾ˆæ„å¤–", "çªç„¶è¯´æƒ³æˆ‘ï¼Ÿæœ‰å•¥å¥½äº‹å—ï¼Ÿ", "å“¼ï¼Œä¸€å¤©åˆ°æ™šå‡€æƒ³è¿™äº›"],
}

# å¾®ä¿¡è¡¨æƒ…åŒ…/Emotion æ˜ å°„
EMOTION_MAP = {
    "[å¾®ç¬‘]": "ğŸ˜Š",
    "[å¯çˆ±]": "ğŸ˜Š",
    "[å¤§ç¬‘]": "ğŸ˜„",
    "[å®³ç¾]": "ğŸ˜Š",
    "[è°ƒçš®]": "ğŸ˜œ",
    "[äº²äº²]": "ğŸ˜˜",
    "[çˆ±å¿ƒ]": "â¤ï¸",
    "[ç«ç‘°]": "ğŸŒ¹",
    "[å’–å•¡]": "â˜•",
    "[è›‹ç³•]": "ğŸ°",
    "[ç¤¼ç‰©]": "ğŸ",
    "[å¤ªé˜³]": "â˜€ï¸",
    "[æœˆäº®]": "ğŸŒ™",
    "[æ˜Ÿæ˜Ÿ]": "â­",
    "[çƒŸèŠ±]": "ğŸ†",
    "[çƒŸèŠ±2]": "ğŸ‡",
    "[é¼“æŒ]": "ğŸ‘",
    "[OK]": "ğŸ‘",
    "[èµ]": "ğŸ‘",
    "[èµ2]": "ğŸ‘",
    "[çˆ±å¿ƒ2]": "ğŸ’•",
    "[çˆ±å¿ƒ3]": "ğŸ’–",
    "[çˆ±å¿ƒ4]": "ğŸ’˜",
    "[çˆ±å¿ƒ5]": "ğŸ’",
    "[çˆ±å¿ƒ6]": "ğŸ’",
    "[çˆ±å¿ƒ7]": "ğŸ’Ÿ",
    "[çˆ±å¿ƒ8]": "â£ï¸",
    "[çˆ±å¿ƒ9]": "ğŸ’•",
    "[çˆ±å¿ƒ10]": "ğŸ’–",
}

# è¡¨æƒ…åŒ…å›å¤è§„åˆ™
EMOTION_REPLIES = {
    "ğŸ˜Š": ["ä½ å‘ä¸ªå¾®ç¬‘è¡¨æƒ…ï¼Œæ˜¯æƒ³è®©æˆ‘ä¹Ÿç¬‘ä¸€ä¸ªå—ï¼Ÿ", "ç¬‘èµ·æ¥çœŸå¥½çœ‹å‘¢ï½"],
    "ğŸ˜„": ["å“ˆå“ˆï¼Œä½ ç¬‘å¾—çœŸå¼€å¿ƒå‘€", "çœ‹åˆ°ä½ ç¬‘ï¼Œæˆ‘ä¹Ÿå¿ä¸ä½ç¬‘äº†"],
    "ğŸ˜˜": ["äº²äº²ï¼Ÿæ˜¯æƒ³æˆ‘äº†å—ï¼Ÿ", "å“å‘€ï¼Œè¿™ä¹ˆå¯çˆ±çš„è¡¨æƒ…"],
    "â¤ï¸": ["å‘ä¸ªçˆ±å¿ƒï¼Ÿæ˜¯åœ¨æš—ç¤ºä»€ä¹ˆå—ï¼Ÿ", "å¿ƒéƒ½åŒ–äº†ï½"],
    "ğŸŒ¹": ["é€æˆ‘ç«ç‘°ï¼Ÿï¼ˆå®³ç¾åœ°æ¥è¿‡ï¼‰", "èŠ±å„¿è™½ç¾ï¼Œä½†ä¸åŠä½ ç¬‘"],
    "ğŸ": ["é€ç¤¼ç‰©ï¼Ÿæ˜¯æœ‰ä»€ä¹ˆå¥½äº‹è¦åº†ç¥å—ï¼Ÿ", "å“‡ï¼Œè¿˜æœ‰ç¤¼ç‰©å‘€ï½"],
    "ğŸ‘": ["ç»™æˆ‘ç‚¹èµï¼Ÿæ˜¯å¤¸æˆ‘èªæ˜å—ï¼Ÿ", "ä½ æ‰æ˜¯æœ€æ£’çš„ï¼"],
    "ğŸ‘": ["ç»™æˆ‘é¼“æŒï¼Ÿæˆ‘æœ‰è¿™ä¹ˆå‰å®³å—ï¼Ÿ", "åˆ«å¤¸æˆ‘äº†ï¼Œä¼šéª„å‚²çš„"],
}


# ==================== å¯¹è¯çŠ¶æ€ç®¡ç† ====================
class ConversationManager:
    def __init__(self, max_history=6):
        self.history = deque(maxlen=max_history * 2)
        self.question_reply_count = {}  # è®°å½•æ¯ä¸ªé—®é¢˜çš„å›å¤æ¬¡æ•°
        self.last_reply_time = time.time()  # ä¸Šæ¬¡å›å¤æ—¶é—´
        self.reply_delay = 1.5  # å›å¤é—´éš”ï¼ˆç§’ï¼‰
        self.current_qa_sequence = {}  # å½“å‰é—®ç­”åºåˆ—

    def add_message(self, sender, text, timestamp=None):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        if timestamp is None:
            timestamp = time.time()

        self.history.append({
            'sender': sender,
            'text': text,
            'timestamp': timestamp
        })

    def should_reply_now(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç«‹å³å›å¤"""
        current_time = time.time()
        time_diff = current_time - self.last_reply_time
        return time_diff >= self.reply_delay

    def get_next_reply(self, question_text):
        """æ ¹æ®é—®é¢˜è·å–ä¸‹ä¸€ä¸ªå›å¤"""
        question_lower = question_text.lower()

        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„é—®ç­”è§„åˆ™
        for key, replies in CUSTOM_QA_RULES.items():
            if key.lower() == question_lower or key.lower() in question_lower:
                # è·å–å½“å‰é—®é¢˜çš„å›å¤ç´¢å¼•
                current_index = self.question_reply_count.get(key, 0)
                reply = replies[current_index % len(replies)]  # å¾ªç¯ä½¿ç”¨
                self.question_reply_count[key] = current_index + 1
                return reply

        return None

    def get_emotion_reply(self, emotion_text):
        """è·å–è¡¨æƒ…åŒ…å¯¹åº”çš„å›å¤"""
        for emotion_key, emoji in EMOTION_MAP.items():
            if emotion_key in emotion_text:
                replies = EMOTION_REPLIES.get(emoji, [])
                if replies:
                    return random.choice(replies)

        # å¦‚æœæ˜¯ emoji è¡¨æƒ…
        if emotion_text in EMOTION_REPLIES:
            return random.choice(EMOTION_REPLIES[emotion_text])

        return None

    def get_history(self):
        """è·å–å¯¹è¯å†å²"""
        return list(self.history)


# ==============================================

def parse_wx_message(msg):
    """
    æ ¹æ®å®é™…å¯¹è±¡ç±»å‹è§£ææ¶ˆæ¯
    æ”¯æŒï¼šæ–‡æœ¬ã€è¡¨æƒ…åŒ…ã€å›¾ç‰‡ã€è¯­éŸ³ç­‰
    """
    try:
        msg_type = type(msg).__name__

        # è‡ªå·±å‘çš„æ¶ˆæ¯
        if msg_type == 'SelfTextMessage':
            return SELF_NICKNAME, getattr(msg, 'content', '').strip()

        # å¯¹æ–¹å‘çš„æ–‡æœ¬æ¶ˆæ¯
        elif msg_type == 'FriendTextMessage':
            return TARGET_CONTACT, getattr(msg, 'content', '').strip()

        # å¯¹æ–¹å‘çš„éæ–‡æœ¬æ¶ˆæ¯
        elif 'Friend' in msg_type and 'Message' in msg_type:
            content = getattr(msg, 'content', getattr(msg, 'text', ''))
            if not content:
                # æ ¹æ®ç±»å‹ç”Ÿæˆæè¿°
                if 'Emotion' in msg_type:
                    content = "[è¡¨æƒ…åŒ…]"
                elif 'Image' in msg_type:
                    content = "[å›¾ç‰‡]"
                elif 'Voice' in msg_type:
                    content = "[è¯­éŸ³]"
                elif 'File' in msg_type:
                    content = "[æ–‡ä»¶]"
                else:
                    content = f"[{msg_type.replace('Friend', '').replace('Message', '')}]"
            return TARGET_CONTACT, content

        # ç³»ç»Ÿæ¶ˆæ¯
        elif msg_type == 'SystemMessage':
            return "SYS", "[ç³»ç»Ÿæ¶ˆæ¯]"
        elif msg_type == 'TimeMessage':
            return "SYS", "[æ—¶é—´]"

        # å…œåº•
        else:
            content = getattr(msg, 'content', getattr(msg, 'text', getattr(msg, 'message', str(msg))))
            return "unknown", content.strip()

    except Exception as e:
        print(f" æ¶ˆæ¯è§£æå¼‚å¸¸: {e}")
        return "error", "[è§£æå¤±è´¥]"


def get_spark_reply(last_message: str, conversation_history: list = None) -> str:
    """è°ƒç”¨æ˜Ÿç«å¤§æ¨¡å‹ç”Ÿæˆæ‹ŸäººåŒ–å›å¤ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰"""
    url = "https://spark-api-open.xf-yun.com/v1/chat/completions"

    # æ„å»ºå¯¹è¯å†å²
    messages = [
        {"role": "system", "content": (
            "ä½ æ˜¯åˆå¤ğŸƒï¼Œä¸€ä¸ªè‡ªä¿¡ï¼Œå¤§æ–¹ï¼Œæœ‰æ—¶è¯´è¯ä¸è¿‡è„‘å­çš„ç”·ç”Ÿã€‚"
            "æ€§æ ¼å†…å‘ï¼Œå¹³å¸¸ä¸æ³¨é‡äº¤é™…ï¼Œçƒ­æƒ…å¼€æœ—ï¼Œä¸å–„äºè¡¨è¾¾"
            "è¯´è¯æ—¶å–œæ¬¢éª‚éª‚å’§å’§ï¼Œå–œæ¬¢å¼€ç©ç¬‘ï¼Œå¤§æ–¹éšæ„ï¼Œæ€§æ ¼éšå’Œï¼Œå’Œå¼‚æ€§è¯´è¯æœ‰ç‚¹æ€¯åœºï¼Œé—·éªšç”·"
            "è¯´è¯å–œæ¬¢å¼€ç©ç¬‘ï¼Œå¾…äººå‹å¥½ï¼Œå¿ƒæƒ…ä¸å¥½ä¼šæ€¼äºº"
            "ä¸æ˜¯è¯ç—¨ï¼Œä½†æ˜¯å–œæ¬¢å’Œæœ‹å‹èŠå¤©"
            "è¯´è¯æ³¨æ„è¨€è¡Œä¸¾æ­¢ï¼Œå®¹æ˜“å†²åŠ¨"
            "æ—¥å¸¸è¯´è¯å¶å°”ä¼šå£åæ–¹è¨€ï¼Œçˆ†ç²—å£ï¼Œå¦‚æ±Ÿè¥¿è¯ï¼Œæ¹–å—è¯ï¼Œå››å·è¯æ–¹è¨€"
            "å¦‚æœå¯¹æ–¹å‘é€çš„æ˜¯[è¡¨æƒ…åŒ…]æˆ–[å›¾ç‰‡]ï¼Œä½ è¦æ ¹æ®ä¸Šä¸‹æ–‡çŒœæµ‹å¯¹æ–¹å¯èƒ½æƒ³è¡¨è¾¾ä»€ä¹ˆï¼Œç„¶åç”¨å¹½é»˜çš„æ–¹å¼å›åº”"
        )}
    ]

    # æ·»åŠ å†å²å¯¹è¯
    if conversation_history:
        for msg in conversation_history[-MAX_HISTORY:]:  # åªå–æœ€è¿‘çš„å¯¹è¯
            if msg['sender'] == TARGET_CONTACT:
                messages.append({"role": "user", "content": msg['text']})
            elif msg['sender'] == SELF_NICKNAME:
                messages.append({"role": "assistant", "content": msg['text']})

    # æ·»åŠ å½“å‰æ¶ˆæ¯
    messages.append({"role": "user", "content": last_message})

    data = {
        "model": "4.0Ultra",
        "messages": messages,
        "temperature": 0.8,
        "max_tokens": 200
    }
    headers = {
        "Authorization": "Bearer kDGPfkUvmLgoJFYSMmlN:KObNnGCjgYoSCCkKXzFH",
        "Content-Type": "application/json"
    }
    try:
        response = requests.post(url, headers=headers, json=data, timeout=10)
        response.raise_for_status()
        reply = response.json()["choices"][0]["message"]["content"]
        return reply.strip()
    except Exception as e:
        print(f" æ˜Ÿç«APIå¼‚å¸¸: {e}")
        return random.choice(["ç½‘ç»œä¸å¥½~", "æ²¡å¬æ¸…ï¼Œå†è¯´ä¸€éï¼Ÿ"])


def predict_sentiment(message: str, tokenizer, model) -> int:
    """æƒ…æ„Ÿåˆ†æï¼š0=è´Ÿå‘, 1=ä¸­æ€§, 2=æ­£å‘"""
    inputs = tokenizer(
        message,
        truncation=True,
        padding='max_length',
        max_length=128,
        return_tensors='pt'
    )
    with torch.no_grad():
        logits = model(**inputs).logits
        _, pred = torch.max(logits, dim=1)
    return pred.item()


def main():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(script_dir, MODEL_DIR_NAME)

    # æ£€æŸ¥æƒ…æ„Ÿæ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f" æƒ…æ„Ÿæ¨¡å‹ä¸å­˜åœ¨: {model_path}")
        print(" è¯·å…ˆè¿è¡Œ train.py ç”Ÿæˆæ¨¡å‹ï¼")
        return

    print(f" åŠ è½½æƒ…æ„Ÿæ¨¡å‹: {model_path}")
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.eval()

    # åˆå§‹åŒ–å¾®ä¿¡
    try:
        wx = WeChat()
        print(f"å¾®ä¿¡è¿æ¥æˆåŠŸï¼ç›‘å¬: '{TARGET_CONTACT}'ï¼Œæˆ‘çš„æ˜µç§°: '{SELF_NICKNAME}'")
    except Exception as e:
        print(f"å¾®ä¿¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # åˆ‡æ¢åˆ°ç›®æ ‡èŠå¤©çª—å£
    print(" æ­£åœ¨åˆ‡æ¢åˆ°èŠå¤©çª—å£...")
    wx.ChatWith(TARGET_CONTACT)
    time.sleep(2.5)
    print(f" å·²é”å®šã€Œ{TARGET_CONTACT}ã€çš„èŠå¤©çª—å£ï¼Œå¼€å§‹ç›‘å¬...")

    processed_messages = set()
    sent_replies = deque(maxlen=5)

    # ==================== åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨ ====================
    conv_manager = ConversationManager()

    try:
        while True:
            all_messages = wx.GetAllMessage()
            recent_messages = all_messages[-15:] if len(all_messages) > 15 else all_messages

            new_msgs = []
            for msg in recent_messages:
                sender, text = parse_wx_message(msg)

                # ä½¿ç”¨ (text, len) ä½œä¸ºå”¯ä¸€é”®
                key = (text, len(text))
                if key in processed_messages:
                    continue
                processed_messages.add(key)

                # å¤„ç†æ‰€æœ‰ç±»å‹çš„æ¶ˆæ¯
                if text and sender != "SYS":
                    new_msgs.append((sender, text))

            # å¤„ç†æ–°æ¶ˆæ¯
            for sender, text in new_msgs:
                if (sender == SELF_NICKNAME or
                        text.strip() in sent_replies or
                        sender == "SYS"):
                    continue

                now = time.strftime("%H:%M:%S")
                print(f"[{now}]  æ”¶åˆ° [{sender}]: {text}")

                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å›å¤ï¼ˆæ—¶é—´é—´éš”æ§åˆ¶ï¼‰
                if not conv_manager.should_reply_now():
                    print(f"[{now}]  ç­‰å¾…å›å¤é—´éš”...")
                    continue

                # ç‰¹æ®Šè§„åˆ™ï¼šå…¨æ˜¯å¥å·/ç‚¹
                if re.fullmatch(r'[ã€‚.]+', text.strip()):
                    reply = "è„‘å­æœ‰æ³¡å—ï¼Œä¸€ç›´å†’æ³¡"
                else:
                    #  æ£€æŸ¥è‡ªå®šä¹‰é—®ç­”è§„åˆ™
                    custom_reply = conv_manager.get_next_reply(text)
                    if custom_reply:
                        reply = custom_reply
                        print(f"[{now}]  ä½¿ç”¨è‡ªå®šä¹‰é—®ç­”è§„åˆ™")
                    else:
                        #  æ£€æŸ¥è¡¨æƒ…åŒ…å›å¤è§„åˆ™
                        emotion_reply = conv_manager.get_emotion_reply(text)
                        if emotion_reply:
                            reply = emotion_reply
                            print(f"[{now}]  ä½¿ç”¨è¡¨æƒ…åŒ…å›å¤è§„åˆ™")
                        else:
                            #  æƒ…æ„Ÿåˆ†æï¼ˆåªå¯¹æ–‡æœ¬æ¶ˆæ¯ï¼‰
                            if not text.startswith('['):  # é [è¡¨æƒ…åŒ…] ç±»å‹
                                try:
                                    sent_label = ['è´Ÿå‘', 'ä¸­æ€§', 'æ­£å‘'][predict_sentiment(text, tokenizer, model)]
                                    print(f"[{now}]  æƒ…æ„Ÿ: {sent_label}")
                                except Exception as e:
                                    print(f"[{now}] æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")

                            #  è°ƒç”¨ AI å›å¤ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
                            reply = get_spark_reply(text, conv_manager.get_history())

                print(f"[{now}]  å›å¤: {reply}")

                # å‘é€å›å¤
                wx.SendMsg(reply)
                sent_replies.append(reply.strip())

                # æ›´æ–°å¯¹è¯å†å²
                conv_manager.add_message(sender, text)
                conv_manager.add_message(SELF_NICKNAME, reply)

                # æ›´æ–°æœ€åå›å¤æ—¶é—´
                conv_manager.last_reply_time = time.time()

            if not new_msgs:
                print(f"[{time.strftime('%H:%M:%S')}]  æ— æ–°æ¶ˆæ¯")

            time.sleep(1.0)  # å‡å°‘ä¸»å¾ªç¯å»¶è¿Ÿï¼Œè®©æ¶ˆæ¯å¤„ç†æ›´åŠæ—¶

    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        import traceback
        print(f" ä¸»å¾ªç¯å¼‚å¸¸: {e}")
        traceback.print_exc()
        time.sleep(2)


if __name__ == "__main__":
    main()